{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "ff = \"wavs_single_channel/BoundaryTone-features-pyin/subj-2108_piano_1obj_mbt_zen.wav_1.wav.npy\"\n",
    "# load features from npy\n",
    "features = np.load(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first non-zero frame\n",
    "non_zero_frames = np.where(features[1] != 0)\n",
    "first_non_zero_frame = non_zero_frames[0][0]\n",
    "y, sr = librosa.load('wavs_single_channel/BoundaryTone/subj-2108_piano_1obj_mbt_zen.wav_1.wav', sr=44100)\n",
    "\n",
    "print(y.shape, sr)\n",
    "print(y.shape[0]/44100)\n",
    "f0, voiced_flag, voiced_probs = librosa.pyin(y,\n",
    "                                            sr=16000,\n",
    "                                            fmin=librosa.note_to_hz('C2'),\n",
    "                                            fmax=librosa.note_to_hz('C7'),\n",
    "                                            fill_na=0.0)\n",
    "\n",
    "print(voiced_flag.shape)\n",
    "\n",
    "f02, voiced_flag2, voiced_probs2 = librosa.pyin(y,\n",
    "                                            sr=44100,\n",
    "                                            fmin=librosa.note_to_hz('C2'),\n",
    "                                            fmax=librosa.note_to_hz('C7'),\n",
    "                                            fill_na=0.0)\n",
    "\n",
    "print(voiced_flag2[-3:])\n",
    "# print(features.shape)\n",
    "# print(features.shape[1]/44100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59072,)\n",
      "118144\n",
      "b'\\xfc\\xff'\n",
      "370\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Error while processing frame",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(frames))\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, frame \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(frames):\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mvad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_speech\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28mprint\u001b[39m(i)\n",
      "File \u001b[0;32m/data/storage025/yzhongenv/lib/python3.10/site-packages/webrtcvad.py:27\u001b[0m, in \u001b[0;36mVad.is_speech\u001b[0;34m(self, buf, sample_rate, length)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m length \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(buf):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuffer has \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m frames, but length argument was \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m     26\u001b[0m             \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(buf) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2.0\u001b[39m), length))\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_webrtcvad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mError\u001b[0m: Error while processing frame"
     ]
    }
   ],
   "source": [
    "import webrtcvad\n",
    "vad = webrtcvad.Vad()\n",
    "vad.set_mode(2)\n",
    "\n",
    "sample_rate = 16000\n",
    "# downsampling from 44100 to 16000 and framing\n",
    "y_16k = librosa.resample(y, orig_sr=sr, target_sr=sample_rate)\n",
    "print(y_16k.shape)\n",
    "# transfer to bytes\n",
    "y_16k = np.int16(y_16k * 32768).tobytes()\n",
    "print(len(y_16k))\n",
    "print(y_16k[:2])\n",
    "# calculate bytes of 10ms in 16000Hz\n",
    "step = int(sample_rate * 0.01) * 2\n",
    "# loop the bytes in 10ms frames\n",
    "frames = []\n",
    "for i in range(0, len(y_16k), step):\n",
    "    frames.append(y_16k[i:i+step])\n",
    "print(len(frames))\n",
    "\n",
    "for i, frame in enumerate(frames):\n",
    "    if vad.is_speech(frame, sample_rate):\n",
    "        print(i)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yzhongenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
