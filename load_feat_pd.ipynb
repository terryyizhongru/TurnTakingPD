{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "base_folder_path = Path('/data/storage025/wavs_single_channel_normalized_nosil/')\n",
    "\n",
    "demo_data_file = '/home/yzhong/gits/TurnTakingPD/demogr_perpp.txt'\n",
    "ID2EMO = {}\n",
    "with open(demo_data_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        datas = line.split('\\t')\n",
    "        ID2EMO[datas[0]] = datas[1:]\n",
    "        \n",
    "\n",
    "# np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "\n",
    "def get_demo(filename):\n",
    "    subject_id = filename.split('_')[0][-4:]\n",
    "    group_id = subject_id[:2]\n",
    "    if group_id not in ['11', '21', '22']:\n",
    "        raise ValueError(f\"Invalid group id {group_id}\")\n",
    "    if subject_id in {'2219', '2123'}:\n",
    "        return None, None, None\n",
    "    if subject_id in {'2135'}:\n",
    "        return subject_id, group_id, ['NA', 'NA', 'NA', 'NA']\n",
    "    return subject_id, group_id, ID2EMO[subject_id]\n",
    "\n",
    "\n",
    "def add2list(group_id, feature, ls):\n",
    "    if group_id == '11':\n",
    "        ls[0].append(feature)\n",
    "    elif group_id == '21':\n",
    "        ls[1].append(feature)\n",
    "    elif group_id == '22':\n",
    "        ls[2].append(feature)\n",
    "    else:\n",
    "        print(f'Invalid group id {group_id}')\n",
    "        \n",
    "       \n",
    "   \n",
    "\n",
    "def load_utt_feat(feature_name='energy', stats='mean'):\n",
    "        # 3 sublists for YA OA PD\n",
    "    exp2lists = {'BoundaryTone': [[], [], []], 'EarlyLate': [[], [], []], 'PictureNaming': [[], [], []]}\n",
    "    avg_diff = []\n",
    "    for folder in ['BoundaryTone', 'EarlyLate', 'PictureNaming']:\n",
    "        feature_folder = os.path.join(base_folder_path, folder + '-features', feature_name)\n",
    "        feature_folder = Path(feature_folder)\n",
    "        npy_files = list(feature_folder.glob('*.npy'))\n",
    "        print(f'Processing {folder} folder...')\n",
    "        print(f'Found {len(npy_files)} npy files')\n",
    "\n",
    "        cnt = 0\n",
    "        for npy_file in npy_files:\n",
    "            feature = np.load(npy_file)         \n",
    "            # check if all 0 value\n",
    "            if np.max(feature) == 0 and np.min(feature) == 0:\n",
    "                cnt += 1\n",
    "                continue\n",
    "            \n",
    "            group_id = get_group_id(npy_file.stem)\n",
    "            feature = feature[feature != 0]\n",
    "            if feature_name == 'f0':\n",
    "                feature = feature[feature < 500.0]\n",
    "                feature = np.log(feature)\n",
    "                if feature.shape[0] == 0:\n",
    "                    print(f'All value larger than 500.0 in {npy_file}')\n",
    "                    continue\n",
    "            if stats == 'mean':\n",
    "                feature = np.mean(feature)\n",
    "            elif stats == 'std':\n",
    "                feature = np.std(feature)\n",
    "            add2list(group_id, (npy_file.stem, feature), exp2lists[folder])\n",
    "        print(f'{cnt} files with all 0 values')\n",
    "        \n",
    "    \n",
    "    all3 = [[], [], []] \n",
    "    for i in range(3):\n",
    "        all3[i] += exp2lists['BoundaryTone'][i] + exp2lists['EarlyLate'][i] + exp2lists['PictureNaming'][i]\n",
    "\n",
    "\n",
    "        \n",
    "    return all3, exp2lists\n",
    "    \n",
    "\n",
    "def load_rp():\n",
    "        # 3 sublists for YA OA PD\n",
    "    exp2lists = {'BoundaryTone': [[], [], []], 'EarlyLate': [[], [], []], 'PictureNaming': [[], [], []]}\n",
    "    \n",
    "    for folder in ['BoundaryTone', 'EarlyLate', 'PictureNaming']:\n",
    "        feature_list = os.path.join('/home/yzhong/gits/TurnTakingPD/filelists', 'clean_id_responsetime_' + folder + '_filtered.txt')\n",
    "        \n",
    "        cnt = 0\n",
    "        with open(feature_list, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                rp = float(line.strip().split('\\t')[-1])\n",
    "                basename = line.strip().split('\\t')[0]\n",
    "                group_id = get_group_id(basename)\n",
    "                add2list(group_id, (basename, rp), exp2lists[folder])\n",
    "                cnt += 1\n",
    "                \n",
    "        print(f'Processing {feature_list} ...')\n",
    "        print(f'Found {cnt}')\n",
    "\n",
    "\n",
    "    all3 = [[], [], []] \n",
    "    for i in range(3):\n",
    "        all3[i] += exp2lists['BoundaryTone'][i] + exp2lists['EarlyLate'][i] + exp2lists['PictureNaming'][i]\n",
    "    \n",
    "    return all3, exp2lists\n",
    "\n",
    "# all3_f0, exp2list_f0 = load_utt_feat(feature_name='f0')\n",
    "# all3_f0_var, exp2list_f0_var = load_utt_feat(feature_name='f0', stats='std')\n",
    "\n",
    "# all3_energy, exp2list_energy = load_utt_feat(feature_name='energy')\n",
    "# all3_energy_var, exp2list_energy_var = load_utt_feat(feature_name='energy', stats='std')\n",
    "\n",
    "# all3_rp, exp2list_rp = load_rp()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PictureNaming folder...\n",
      "Found 1652 npy files\n",
      "All value larger than 500.0 in /data/storage025/wavs_single_channel_normalized_nosil/PictureNaming-features/f0/subj-2112_rups.png_1.wav_f0.npy\n",
      "All value larger than 500.0 in /data/storage025/wavs_single_channel_normalized_nosil/PictureNaming-features/f0/subj-2202_schatkist.png_1.wav_f0.npy\n",
      "All value larger than 500.0 in /data/storage025/wavs_single_channel_normalized_nosil/PictureNaming-features/f0/subj-2127_rups.png_1.wav_f0.npy\n",
      "All value larger than 500.0 in /data/storage025/wavs_single_channel_normalized_nosil/PictureNaming-features/f0/subj-2120_kaars.png_1.wav_f0.npy\n",
      "0 files with all 0 values\n",
      "Processing EarlyLate folder...\n",
      "Found 3971 npy files\n",
      "All value larger than 500.0 in /data/storage025/wavs_single_channel_normalized_nosil/EarlyLate-features/f0/subj-2112_41_L_gereedschap_tanden.wav_1.wav_f0.npy\n",
      "All value larger than 500.0 in /data/storage025/wavs_single_channel_normalized_nosil/EarlyLate-features/f0/subj-2120_17_E_piept_knaagdier.wav_1.wav_f0.npy\n",
      "0 files with all 0 values\n",
      "Processing BoundaryTone folder...\n",
      "Found 5026 npy files\n",
      "0 files with all 0 values\n",
      "{'experiment': 'exp_1_PictureNaming', 'group_id': '21', 'value': array([208.85526661, 211.28204791, 213.73702705, 214.97519306,\n",
      "       218.73289324, 222.55627687, 227.75828325, 230.40470702,\n",
      "       233.08188076, 237.15608027, 242.69934088, 251.25811465,\n",
      "       254.17759331, 252.7136381 , 251.25811465, 255.65002913,\n",
      "       239.91170119]), 'subject_id': '2118', 'filename': 'subj-2118_wenkbrauw.png_1.wav_f0', 'age': '71', 'gender': 'V', 'moca': '30', 'education': '7'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_frame_feat(feature_name='energy', stats='mean', log_value=False):\n",
    "        # 3 sublists for YA OA PD\n",
    "    all_data = []\n",
    "\n",
    "    exp2lists = {'BoundaryTone': [[], [], []], 'EarlyLate': [[], [], []], 'PictureNaming': [[], [], []]}\n",
    "    avg_diff = []\n",
    "    for exp_idx, folder in enumerate(['PictureNaming', 'EarlyLate', 'BoundaryTone']):\n",
    "        feature_folder = os.path.join(base_folder_path, folder + '-features', feature_name)\n",
    "        feature_folder = Path(feature_folder)\n",
    "        npy_files = list(feature_folder.glob('*.npy'))\n",
    "        print(f'Processing {folder} folder...')\n",
    "        print(f'Found {len(npy_files)} npy files')\n",
    "\n",
    "        cnt = 0\n",
    "        for npy_file in npy_files:\n",
    "            feature = np.load(npy_file)         \n",
    "            # check if all 0 value\n",
    "            if np.max(feature) == 0 and np.min(feature) == 0:\n",
    "                cnt += 1\n",
    "                continue\n",
    "            \n",
    "            subject_id, group_id, demo_data = get_demo(npy_file.stem)\n",
    "            if subject_id is None:\n",
    "                continue\n",
    "            feature = feature[feature != 0]\n",
    "            if feature_name == 'f0':\n",
    "                feature = feature[feature < 500.0]\n",
    "                if feature.shape[0] == 0:\n",
    "                    print(f'All value larger than 500.0 in {npy_file}')\n",
    "                    continue\n",
    "\n",
    "            if log_value is True:              \n",
    "                feature = np.log(feature)\n",
    "\n",
    "\n",
    "            item = {\n",
    "                    'experiment': 'exp_' + str(exp_idx + 1) + '_' + folder,\n",
    "                    'group_id': group_id,\n",
    "                    'value': feature,\n",
    "                    'subject_id':subject_id,\n",
    "                    'filename': npy_file.stem,\n",
    "                    'age': demo_data[0],\n",
    "                    'gender': demo_data[1],\n",
    "                    'moca': demo_data[2],\n",
    "                    'education': demo_data[3],\n",
    "                }\n",
    "            all_data.append(item)\n",
    "\n",
    "            # if stats == 'mean':\n",
    "            #     feature = np.mean(feature)\n",
    "            # elif stats == 'std':\n",
    "            #     feature = np.std(feature)\n",
    "            \n",
    "            # add2list(group_id, (npy_file.stem, feature), exp2lists[folder])\n",
    "        print(f'{cnt} files with all 0 values')\n",
    "        \n",
    "    \n",
    "    # all3 = [[], [], []] \n",
    "    # for i in range(3):\n",
    "    #     all3[i] += exp2lists['BoundaryTone'][i] + exp2lists['EarlyLate'][i] + exp2lists['PictureNaming'][i]\n",
    "\n",
    "        \n",
    "    return all_data\n",
    "    \n",
    "\n",
    "metadata = load_frame_feat(feature_name='f0')\n",
    "print(metadata[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341788 230872\n",
      "              level  OA_values  PD_values     OA_mean     PD_mean     OA_std  \\\n",
      "0             frame     341788     230872  155.761030  157.979382  47.209862   \n",
      "1    utterance_mean       4928       3085  151.909254  153.508686  35.380188   \n",
      "2     utterance_std       4928       3085   24.368925   19.790064  12.843787   \n",
      "3  person_mean_mean         33         20  152.763959  153.270252  30.845278   \n",
      "4   person_std_mean         33         20   17.134302   12.733547   4.572721   \n",
      "5   person_mean_std         33         20   24.434859   19.767887   5.776995   \n",
      "6    person_std_std         33         20   11.193803    9.698034   2.317227   \n",
      "\n",
      "      PD_std   OA_median   PD_median  p_ks1          p_ks2           p_kw  \\\n",
      "0  45.299326  150.264428  157.371053    0.0   0.000000e+00  1.078665e-156   \n",
      "1  36.802806  148.071497  153.944591    0.0   0.000000e+00   4.795595e-02   \n",
      "2  11.448280   22.486293   16.867276    0.0   0.000000e+00   3.923598e-76   \n",
      "3  34.385554  145.395567  153.717728    0.0   0.000000e+00   1.000000e+00   \n",
      "4   3.751534   17.745028   12.215852    0.0  1.142058e-292   1.409030e-03   \n",
      "5   5.805158   25.485394   19.125639    0.0   0.000000e+00   8.234191e-03   \n",
      "6   1.971870   11.366346    9.393215    0.0  4.591468e-218   2.639998e-02   \n",
      "\n",
      "          p_lev  \n",
      "0  3.568603e-05  \n",
      "1  1.696216e-09  \n",
      "2  2.383846e-15  \n",
      "3  3.895209e-01  \n",
      "4  1.152847e-01  \n",
      "5  6.887946e-01  \n",
      "6  4.304856e-01  \n",
      "48119 32776\n",
      "70529 47982\n",
      "223140 150114\n",
      "              level  OA_values  PD_values     OA_mean     PD_mean     OA_std  \\\n",
      "0             frame      48119      32776  162.522634  168.642671  51.839394   \n",
      "1    utterance_mean        998        621  153.970074  158.193976  36.966157   \n",
      "2     utterance_std        998        621   21.837124   18.926962  15.015404   \n",
      "3  person_mean_mean         32         20  153.701694  157.511551  30.528914   \n",
      "4   person_std_mean         32         20   20.192220   16.661501   7.182801   \n",
      "5   person_mean_std         32         20   21.824872   18.891663   6.742792   \n",
      "6    person_std_std         32         20   13.069879   11.841217   4.553732   \n",
      "\n",
      "      PD_std   OA_median   PD_median          p_ks1          p_ks2  \\\n",
      "0  49.891081  152.010417  167.694673   0.000000e+00   0.000000e+00   \n",
      "1  38.323118  147.674821  158.874306   0.000000e+00   0.000000e+00   \n",
      "2  13.488033   17.502015   14.901211   0.000000e+00   0.000000e+00   \n",
      "3  34.117783  145.766605  155.728598   0.000000e+00   0.000000e+00   \n",
      "4   6.956870   20.430131   15.864820   0.000000e+00  4.115939e-276   \n",
      "5   6.164242   20.981782   16.818727   0.000000e+00   0.000000e+00   \n",
      "6   3.089975   12.673845   11.897154  2.458826e-176  1.322401e-247   \n",
      "\n",
      "            p_kw     p_lev  \n",
      "0  7.935465e-101  0.495459  \n",
      "1   2.139294e-02  0.000158  \n",
      "2   4.220765e-06  0.005295  \n",
      "3   6.790241e-01  0.279886  \n",
      "4   6.808250e-02  0.971414  \n",
      "5   7.705526e-02  0.344134  \n",
      "6   3.374316e-01  0.379165  \n",
      "              level  OA_values  PD_values     OA_mean     PD_mean     OA_std  \\\n",
      "0             frame      70529      47982  152.405716  157.323819  43.054463   \n",
      "1    utterance_mean       1757       1106  152.108927  153.871515  36.059767   \n",
      "2     utterance_std       1757       1106   22.685160   17.771411  12.114655   \n",
      "3  person_mean_mean         32         20  151.615348  153.648683  32.872640   \n",
      "4   person_std_mean         32         20   14.666828    9.465541   5.788928   \n",
      "5   person_mean_std         32         20   22.612248   17.758587   7.018065   \n",
      "6    person_std_std         32         20    9.511218    6.677872   3.094055   \n",
      "\n",
      "      PD_std   OA_median   PD_median          p_ks1         p_ks2  \\\n",
      "0  43.498682  147.682975  156.464662   0.000000e+00  0.000000e+00   \n",
      "1  37.878293  147.471454  152.467132   0.000000e+00  0.000000e+00   \n",
      "2  10.345549   20.602503   14.840861   0.000000e+00  0.000000e+00   \n",
      "3  36.444711  143.504321  152.582298   0.000000e+00  0.000000e+00   \n",
      "4   4.445094   13.946257    8.277074   0.000000e+00  3.828740e-99   \n",
      "5   7.314381   21.188732   16.701410   0.000000e+00  0.000000e+00   \n",
      "6   3.053755    8.998573    5.947581  1.431816e-213  2.490806e-39   \n",
      "\n",
      "           p_kw         p_lev  \n",
      "0  4.922889e-96  2.681510e-40  \n",
      "1  4.430786e-01  2.001098e-07  \n",
      "2  4.773968e-39  1.405553e-09  \n",
      "3  9.849936e-01  2.608284e-01  \n",
      "4  4.360287e-04  2.327322e-01  \n",
      "5  8.000454e-03  7.844934e-01  \n",
      "6  5.773808e-04  6.376339e-01  \n",
      "              level  OA_values  PD_values     OA_mean     PD_mean     OA_std  \\\n",
      "0             frame     223140     150114  155.363455  155.860693  47.274369   \n",
      "1    utterance_mean       2173       1358  150.801329  151.070649  34.008765   \n",
      "2     utterance_std       2173       1358   26.893136   21.828810  11.844128   \n",
      "3  person_mean_mean         32         20  150.745673  151.009672  31.153959   \n",
      "4   person_std_mean         32         20   13.223140   10.141074   3.891248   \n",
      "5   person_mean_std         32         20   26.884607   21.819006   6.413272   \n",
      "6    person_std_std         32         20    9.754736    9.073737   2.360436   \n",
      "\n",
      "      PD_std   OA_median   PD_median          p_ks1          p_ks2  \\\n",
      "0  44.477514  150.264428  155.563492   0.000000e+00   0.000000e+00   \n",
      "1  34.938711  148.636634  152.624373   0.000000e+00   0.000000e+00   \n",
      "2  10.934380   25.357110   19.270180   0.000000e+00   0.000000e+00   \n",
      "3  33.394142  147.606380  152.945571   0.000000e+00   0.000000e+00   \n",
      "4   2.265519   13.109778    9.597355   0.000000e+00  8.279489e-143   \n",
      "5   5.737383   28.734884   21.904254   0.000000e+00   0.000000e+00   \n",
      "6   2.358408    9.760276    8.231413  2.663747e-216  2.241722e-189   \n",
      "\n",
      "           p_kw         p_lev  \n",
      "0  1.135484e-28  2.495042e-42  \n",
      "1  6.156341e-01  1.471246e-01  \n",
      "2  2.612261e-45  6.710255e-05  \n",
      "3  9.400274e-01  7.344458e-01  \n",
      "4  8.937571e-03  6.281737e-03  \n",
      "5  9.971525e-03  5.396131e-01  \n",
      "6  2.590952e-01  9.581886e-01  \n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openpyxl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 167\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mprint\u001b[39m(res_df_BoundaryTone)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# write all these res to one excel file and one sheet for each experiment\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mframe_level_analysis.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[1;32m    168\u001b[0m     res_df_allexp\u001b[38;5;241m.\u001b[39mto_excel(writer, sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_exp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    169\u001b[0m     res_df_PictureNaming\u001b[38;5;241m.\u001b[39mto_excel(writer, sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPictureNaming\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/data/storage025/yzhongenv/lib/python3.10/site-packages/pandas/io/excel/_openpyxl.py:57\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[0;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     46\u001b[0m     path: FilePath \u001b[38;5;241m|\u001b[39m WriteExcelBuffer \u001b[38;5;241m|\u001b[39m ExcelWriter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Use the openpyxl module as the Excel writer.\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[1;32m     59\u001b[0m     engine_kwargs \u001b[38;5;241m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     62\u001b[0m         path,\n\u001b[1;32m     63\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[1;32m     67\u001b[0m     )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openpyxl'"
     ]
    }
   ],
   "source": [
    "from scipy.stats import shapiro, kruskal, kstest, norm, levene\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def basic_stats(group1, group2, groupnames=['OA(HC)', 'PD']):\n",
    "\n",
    "    for i, group in enumerate([group1, group2]):\n",
    "        # print(f'\\n  stats of {groupnames[0]}')\n",
    "        # # merge all data in subgroup\n",
    "        # print(group.shape)\n",
    "        # check if nan in subgroup\n",
    "        if np.isnan(group).any():\n",
    "            print('nan in subgroup')\n",
    "\n",
    "        yield np.mean(group), np.std(group), np.median(group)\n",
    "        \n",
    "\n",
    "\n",
    "def stats_test(group1, group2, groupnames=['OA(HC)', 'PD']):\n",
    "\n",
    "\n",
    "    d_stat, p_ks1 = kstest(group1, 'norm')\n",
    "    # print(f\"{groupnames[0]} kstest p-value: {p_ks1}\")\n",
    " \n",
    "    d_stat, p_ks2 = kstest(group2, 'norm')\n",
    "    # print(f\"{groupnames[1]} kstest p-value: {p_ks2}\")\n",
    " \n",
    "    stat, p_kw = kruskal(group1, group2)\n",
    "    # print(f\"Kruskal-Wallis test p value between group {groupnames[0]} and {groupnames[1]} : {p_kw}\")\n",
    "\n",
    "  \n",
    "    levene_stat, p_lev = levene(group1, group2, center='median')\n",
    "    # print(f\"Levene test p value between group {groupnames[0]} and {groupnames[1]} : {p_lev}\")\n",
    "\n",
    "    return p_ks1, p_ks2, p_kw, p_lev\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "df = pd.DataFrame(metadata)\n",
    "\n",
    "# change value to mean of the array\n",
    "# delete all item in dataframe with group id equal to 11\n",
    "df = df[df['group_id'] != '11']\n",
    "\n",
    "\n",
    "def all_level_analysis(df):\n",
    "\n",
    "    item = {}\n",
    "    heads = ['level', 'OA_values', 'PD_values', 'OA_mean', 'PD_mean', 'OA_std', 'PD_std', 'OA_median', 'PD_median', 'p_ks1', 'p_ks2', 'p_kw', 'p_lev']\n",
    "    result_datas = []\n",
    "    \n",
    "    # frame level analysis\n",
    "    OA_values = np.concatenate(df[df['group_id'] == '21']['value'].values)\n",
    "    PD_values = np.concatenate(df[df['group_id'] == '22']['value'].values)\n",
    "    print(len(OA_values), len(PD_values))\n",
    "    OA_stats, PD_stats = basic_stats(OA_values, PD_values, groupnames=['OA', 'PD'])\n",
    "    p_ks1, p_ks2, p_kw, p_lev = stats_test(OA_values, PD_values, groupnames=['OA', 'PD'])\n",
    "    reses = ['frame', len(OA_values), len(PD_values), OA_stats[0], PD_stats[0], OA_stats[1], PD_stats[1], OA_stats[2], PD_stats[2], p_ks1, p_ks2, p_kw, p_lev]\n",
    "    # assign the values to the item\n",
    "    for k, v in zip(heads, reses):\n",
    "        item[k] = v\n",
    "        \n",
    "    result_datas.append(item.copy())\n",
    "\n",
    "    # utterance level\n",
    "    # mean\n",
    "    df_utt_mean = df.copy()\n",
    "    df_utt_mean['value'] = df['value'].apply(lambda x: np.mean(x))\n",
    "    OA_values = np.array(df_utt_mean[df_utt_mean['group_id'] == '21']['value'].values)\n",
    "    PD_values = np.array(df_utt_mean[df_utt_mean['group_id'] == '22']['value'].values)\n",
    "    OA_stats, PD_stats = basic_stats(OA_values, PD_values, groupnames=['OA', 'PD'])\n",
    "    p_ks1, p_ks2, p_kw, p_lev = stats_test(OA_values, PD_values, groupnames=['OA', 'PD'])\n",
    "    reses = ['utterance_mean', len(OA_values), len(PD_values), OA_stats[0], PD_stats[0], OA_stats[1], PD_stats[1], OA_stats[2], PD_stats[2], p_ks1, p_ks2, p_kw, p_lev]\n",
    "    # assign the values to the item\n",
    "    for k, v in zip(heads, reses):\n",
    "        item[k] = v\n",
    "        \n",
    "    result_datas.append(item.copy())\n",
    "    \n",
    "\n",
    "    # std\n",
    "    df_utt_std = df.copy()\n",
    "    df_utt_std['value'] = df['value'].apply(lambda x: np.std(x))\n",
    "    OA_values = np.array(df_utt_std[df_utt_std['group_id'] == '21']['value'].values)\n",
    "    PD_values = np.array(df_utt_std[df_utt_std['group_id'] == '22']['value'].values)\n",
    "    OA_stats, PD_stats = basic_stats(OA_values, PD_values, groupnames=['OA', 'PD'])\n",
    "    p_ks1, p_ks2, p_kw, p_lev = stats_test(OA_values, PD_values, groupnames=['OA', 'PD'])\n",
    "    reses = ['utterance_std', len(OA_values), len(PD_values), OA_stats[0], PD_stats[0], OA_stats[1], PD_stats[1], OA_stats[2], PD_stats[2], p_ks1, p_ks2, p_kw, p_lev]\n",
    "    # assign the values to the item\n",
    "    for k, v in zip(heads, reses):\n",
    "        item[k] = v\n",
    "        \n",
    "    result_datas.append(item.copy())\n",
    "\n",
    "    # person level\n",
    "    # mean of mean of all utterances\n",
    "    df_person_mean_mean = df.copy()\n",
    "    df_person_mean_mean['value'] = df['value'].apply(lambda x: np.mean(x))\n",
    "    OA_values = np.array(df_person_mean_mean[df_person_mean_mean['group_id'] == '21'].groupby('subject_id')['value'].mean().values)\n",
    "    PD_values = np.array(df_person_mean_mean[df_person_mean_mean['group_id'] == '22'].groupby('subject_id')['value'].mean().values)\n",
    "    OA_stats, PD_stats = basic_stats(OA_values, PD_values, groupnames=['OA', 'PD'])\n",
    "    p_ks1, p_ks2, p_kw, p_lev = stats_test(OA_values, PD_values, groupnames=['OA', 'PD'])\n",
    "    reses = ['person_mean_mean', len(OA_values), len(PD_values), OA_stats[0], PD_stats[0], OA_stats[1], PD_stats[1], OA_stats[2], PD_stats[2], p_ks1, p_ks2, p_kw, p_lev]\n",
    "    # assign the values to the item\n",
    "    for k, v in zip(heads, reses):\n",
    "        item[k] = v\n",
    "        \n",
    "    result_datas.append(item.copy())\n",
    "    \n",
    "    # std of mean of all utterances\n",
    "    df_person_std_mean= df.copy()\n",
    "    df_person_std_mean['value'] = df['value'].apply(lambda x: np.mean(x))\n",
    "    OA_values = np.array(df_person_std_mean[df_person_std_mean['group_id'] == '21'].groupby('subject_id')['value'].std().values)\n",
    "    PD_values = np.array(df_person_std_mean[df_person_std_mean['group_id'] == '22'].groupby('subject_id')['value'].std().values)\n",
    "    OA_stats, PD_stats = basic_stats(OA_values, PD_values, groupnames=['OA', 'PD'])\n",
    "    p_ks1, p_ks2, p_kw, p_lev = stats_test(OA_values, PD_values, groupnames=['OA', 'PD'])\n",
    "    reses = ['person_std_mean', len(OA_values), len(PD_values), OA_stats[0], PD_stats[0], OA_stats[1], PD_stats[1], OA_stats[2], PD_stats[2], p_ks1, p_ks2, p_kw, p_lev]\n",
    "    # assign the values to the item\n",
    "    for k, v in zip(heads, reses):\n",
    "        item[k] = v\n",
    "        \n",
    "    result_datas.append(item.copy())\n",
    "\n",
    "    # mean of std of all utterances\n",
    "    df_person_mean_std = df.copy()\n",
    "    df_person_mean_std['value'] = df['value'].apply(lambda x: np.std(x))\n",
    "    OA_values = np.array(df_person_mean_std[df_person_mean_std['group_id'] == '21'].groupby('subject_id')['value'].mean().values)\n",
    "    PD_values = np.array(df_person_mean_std[df_person_mean_std['group_id'] == '22'].groupby('subject_id')['value'].mean().values)\n",
    "    OA_stats, PD_stats = basic_stats(OA_values, PD_values, groupnames=['OA', 'PD'])\n",
    "    p_ks1, p_ks2, p_kw, p_lev = stats_test(OA_values, PD_values, groupnames=['OA', 'PD'])\n",
    "    reses = ['person_mean_std', len(OA_values), len(PD_values), OA_stats[0], PD_stats[0], OA_stats[1], PD_stats[1], OA_stats[2], PD_stats[2], p_ks1, p_ks2, p_kw, p_lev]\n",
    "    # assign the values to the item\n",
    "    for k, v in zip(heads, reses):\n",
    "        item[k] = v\n",
    "        \n",
    "    result_datas.append(item.copy())\n",
    "    \n",
    "    # std of std of all utterances\n",
    "    df_person_std_std = df.copy()\n",
    "    df_person_std_std['value'] = df['value'].apply(lambda x: np.std(x))\n",
    "    OA_values = np.array(df_person_std_std[df_person_std_std['group_id'] == '21'].groupby('subject_id')['value'].std().values)\n",
    "    PD_values = np.array(df_person_std_std[df_person_std_std['group_id'] == '22'].groupby('subject_id')['value'].std().values)\n",
    "    OA_stats, PD_stats = basic_stats(OA_values, PD_values, groupnames=['OA', 'PD'])\n",
    "    p_ks1, p_ks2, p_kw, p_lev = stats_test(OA_values, PD_values, groupnames=['OA', 'PD'])\n",
    "    reses = ['person_std_std', len(OA_values), len(PD_values), OA_stats[0], PD_stats[0], OA_stats[1], PD_stats[1], OA_stats[2], PD_stats[2], p_ks1, p_ks2, p_kw, p_lev]\n",
    "    # assign the values to the item\n",
    "    for k, v in zip(heads, reses):\n",
    "        item[k] = v\n",
    "        \n",
    "    result_datas.append(item.copy())\n",
    "    \n",
    "    return result_datas\n",
    "# generate excel file to write the results\n",
    "\n",
    "res_df_allexp = pd.DataFrame(all_level_analysis(df))\n",
    "# print(res_df_allexp)\n",
    "\n",
    "res_df_PictureNaming = pd.DataFrame(all_level_analysis(df[df['experiment'] == 'exp_1_PictureNaming']))\n",
    "res_df_EarlyLate = pd.DataFrame(all_level_analysis(df[df['experiment'] == 'exp_2_EarlyLate']))\n",
    "res_df_BoundaryTone = pd.DataFrame(all_level_analysis(df[df['experiment'] == 'exp_3_BoundaryTone']))\n",
    "\n",
    "# print(res_df_PictureNaming)\n",
    "# print(res_df_EarlyLate)\n",
    "# print(res_df_BoundaryTone)\n",
    "\n",
    "# write all these res to one excel file and one sheet for each experiment\n",
    "with pd.ExcelWriter('frame_level_analysis.xlsx') as writer:\n",
    "    res_df_allexp.to_excel(writer, sheet_name='all_exp')\n",
    "    res_df_PictureNaming.to_excel(writer, sheet_name='PictureNaming')\n",
    "    res_df_EarlyLate.to_excel(writer, sheet_name='EarlyLate')\n",
    "    res_df_BoundaryTone.to_excel(writer, sheet_name='BoundaryTone')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "groups = ['YA', 'OA', 'PD']\n",
    "\n",
    "def lme(exp2list):\n",
    "    all_data = []\n",
    "\n",
    "    for exp_idx, exp in enumerate(['PictureNaming', 'EarlyLate', 'BoundaryTone']):\n",
    "        experiment_data = exp2list[exp]\n",
    "        for group_idx, group_array in enumerate(experiment_data):\n",
    "            if group_idx == 0:\n",
    "                continue\n",
    "            for value in group_array:\n",
    "                utt = {\n",
    "                    'experiment': 'exp_' + str(exp_idx + 1) + '_' + exp,\n",
    "                    'group': groups[group_idx],\n",
    "                    'value': value[1],\n",
    "                    'subject_id': int(value[0].split('-')[1].split('_')[0])\n",
    "                }\n",
    "                all_data.append(utt)\n",
    "\n",
    "    df = pd.DataFrame(all_data)\n",
    "\n",
    "    model = smf.mixedlm(\"value ~ group + experiment + group:experiment\", \n",
    "                        data=df, \n",
    "                        groups=\"subject_id\")\n",
    "                        \n",
    "\n",
    "    result = model.fit()\n",
    "\n",
    "    print(result.summary())\n",
    "\n",
    "lme(exp2list_f0)\n",
    "# lme(exp2list_f0_var)\n",
    "# lme(exp2list_energy)\n",
    "# lme(exp2list_energy_var)\n",
    "# lme(exp2list_rp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yzhongenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
